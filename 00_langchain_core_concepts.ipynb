{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada59e30-d4f4-44da-ac71-665b7a859c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import MessagesState\n",
    "from IPython.display import Image, display\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7654f-01dd-4760-9a8c-1390420c6e73",
   "metadata": {},
   "source": [
    "## Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2322ecbb-0e3e-4cec-9d3f-bf9f71c8205e",
   "metadata": {},
   "source": [
    "### Message Types\n",
    "\n",
    "- Human message\n",
    "- AI message\n",
    "- System message\n",
    "- Tool message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb01cea-71a2-458d-b16b-37b1441d04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system message to set the context\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a smart and fun specialist in languages, your job is to help the users find slang and expressions alternatives in other languages. You always responds in a humorous manner.\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"Hello there, good morning ! What slang do you want to tranlate in which language ?\",\n",
    "        name=\"Model\",\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"I would like to find the equivalent expression 'bouncing up' in Portuguese.\",\n",
    "        name=\"User\",\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"Sure! Here we go, I'm thinking.... searching... a equivalent expression could be: 'dar a volta por cima'\",\n",
    "        name=\"Model\",\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Could you give me more similar expressions ?\", name=\"User\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "for msg in messages:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb02719-ed5f-4010-9e47-31ef5c4b3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "response = llm_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9c1b7-963c-4647-a410-9390a96e53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94cdccf-cbe3-45b7-8c42-15b713bf785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(vars(response), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28bbef7-bdc3-43b9-bf3f-a702cbb423d9",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb107c-edf0-45ad-812e-6babeced0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_values(a, b):\n",
    "    \"\"\"\n",
    "    Sum two values and return the result.\n",
    "\n",
    "    Parameters:\n",
    "        a (float): The first value.\n",
    "        b (float): The second value.\n",
    "\n",
    "    Returns:\n",
    "        float: The sum of a and b.\n",
    "    \"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb52d2-ce9a-4cf3-a8c9-20beb4973c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_tool = llm_model.bind_tools([sum_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdefea8c-3a2f-4030-88ef-17e12995d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tool = llm_model_tool.invoke(\n",
    "    [HumanMessage(content=\"What is 77 added to 3 ?\", name=\"User\")]\n",
    ")\n",
    "print(json.dumps(vars(response_tool), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311745c-e260-4f77-9523-b7c912a21ac2",
   "metadata": {},
   "source": [
    "## Messages + State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f1061-632d-4fbb-9b55-a088c860b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateMessageBased(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0eaab-c72e-4f70-a97e-ef8d4c5e8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a smart and fun specialist in languages, your job is to help the users find slang and expressions alternatives in other languages. You always responds in a humorous manner.\"\n",
    "    )\n",
    "]\n",
    "new_message = AIMessage(\n",
    "    content=\"Hello there, good morning ! What slang do you want to tranlate in which language ?\",\n",
    "    name=\"Model\",\n",
    ")\n",
    "\n",
    "add_messages(messages, new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee076d7-68fd-4e51-b051-620797c64c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateMessageBased(MessagesState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46785e-220f-443c-bcc9-3c90ccd432c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node\n",
    "def llm_with_tool(state: StateMessageBased):\n",
    "    return {\"messages\": [llm_model_tool.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9897e9-a9fd-45ab-ae95-aee9c6de21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(StateMessageBased)\n",
    "builder.add_node(\"llm_with_tool\", llm_with_tool)\n",
    "builder.add_edge(START, \"llm_with_tool\")\n",
    "builder.add_edge(\"llm_with_tool\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd274d7c-897a-47d6-8e69-4c96939e7d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke(\n",
    "    {\"messages\": HumanMessage(content=\"Hello there, who are you ?\")}\n",
    ")\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6af8bf-512c-494f-a0fa-9b5d4c847617",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke(\n",
    "    {\"messages\": HumanMessage(content=\"Ok how are you today ??\")}\n",
    ")\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7553ac-030b-40f1-997c-0913a17c1521",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke(\n",
    "    {\"messages\": HumanMessage(content=\"What is 77 added to 3 ?\")}\n",
    ")\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f4698-84b4-40bf-a0e1-f03402410b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"messages\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52518fe6-1844-4dce-9267-a4e68bd2d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"messages\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934793c4-4748-4ae3-9a46-b811db638197",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8bfc0-6733-4c60-9554-f6a72e713939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa691133-38f1-42ae-85ba-1da5e5d69375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cd5b8af-e6bb-4fbf-b9db-e1d36de2076a",
   "metadata": {},
   "source": [
    "# Routers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78e11e-1ba1-420a-b5b9-6129ccdbcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_tracker_api_call(package_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches an extended package delivery report, including current location, days ongoing and estimated remaining delivery time\n",
    "    given a package tracking id.\n",
    "\n",
    "    Parameters:\n",
    "        package_id (str): The ID of the package to be tracked.\n",
    "\n",
    "    Returns:\n",
    "        str: A detailed report of the current package delivery status as a text message.\n",
    "    \"\"\"\n",
    "\n",
    "    response_payload = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb55bd8-e128-49f3-95d8-f05940cc1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_tracker_api_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33442ed6-ef73-4594-a7e4-fd5ce9089dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lab-kernel",
   "language": "python",
   "name": "ml-lab-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
