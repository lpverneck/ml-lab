{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74532c91-d351-48ec-a213-8f17b63ddff5",
   "metadata": {},
   "source": [
    "## Building Blocks of DSPy\n",
    "\n",
    "- **dspy.Signature**: define the input/output contract of DSPy module.\n",
    "- **dspy.Module**: define the logic of interacting with LLMs.\n",
    "\n",
    "## Advantages\n",
    "\n",
    "- LM-agnostic programming\n",
    "- Seamless productization\n",
    "- Automatic program optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1657bb-5b38-452a-82c0-479f3fe77a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dspy\n",
    "import mlflow\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "dspy.settings.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"), track_usage=True)\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"my-local-experiment-part-1\")\n",
    "mlflow.dspy.autolog(\n",
    "    log_evals=True, log_compiles=True, log_traces_from_compile=True\n",
    ")\n",
    "mlflow.tracing.disable_notebook_display()\n",
    "\n",
    "# running local MLflow server\n",
    "# mlflow server --host 127.0.0.1 --port 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4349fe8f-b531-4f77-a3d2-cc1c3de068cc",
   "metadata": {},
   "source": [
    "## Class-based Signature Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb30c9f-5691-4af6-a80d-e5eb84071c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlangEquivalence(dspy.Signature):\n",
    "    \"\"\"Find a Portuguese slang equivalance in English and classify it's formality level.\"\"\"\n",
    "\n",
    "    # inputs\n",
    "    portuguese_slang: str = dspy.InputField()\n",
    "    # outputs\n",
    "    english_slang: str = dspy.OutputField()\n",
    "    alternative_slangs: list[str] = dspy.OutputField(\n",
    "        desc=\"More equivalent alternative slangs.\"\n",
    "    )\n",
    "    formality_level: Literal[\"L1\", \"L2\", \"L3\", \"L4\", \"L5\"] = dspy.OutputField(\n",
    "        desc=\"Slang formality level. Lesser the number more informal.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef6efc-e506-4951-8fb7-cf4d40b29139",
   "metadata": {},
   "source": [
    "## String-based Signature Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8602339-07f1-426a-aa66-412eff5c558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_equivalance = dspy.make_signature(\n",
    "    \"portuguese_slang -> english_slang: str, alternative_slangs: list[str]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd220fd9-776a-4cf8-9aac-ecdc20b0b2b8",
   "metadata": {},
   "source": [
    "## LM Interaction via Module Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9197e36-3e47-44cf-b875-d75024b02aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = dspy.Predict(slang_equivalance)\n",
    "output = predict(portuguese_slang=\"Boiar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3cf4905-c27a-4574-96d5-bd8030c7bafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    english_slang='To be clueless or to not understand something.',\n",
       "    alternative_slangs=['to zone out', 'to space out', 'to be lost', 'to be in the dark']\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d0fe47-f747-4488-81d6-7aee0c90127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English equivalent slang: To be clueless or to not understand something.\n",
      "Alternative slangs: ['to zone out', 'to space out', 'to be lost', 'to be in the dark']\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"English equivalent slang: {output['english_slang']}\\nAlternative slangs: {output.alternative_slangs}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3862b56-8040-4d97-a992-fe421d4c0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot = dspy.ChainOfThought(SlangEquivalence)\n",
    "output = cot(portuguese_slang=\"quebrar o galho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f61253-4975-4f69-aeed-b54e1bb329b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='\"Quebrar o galho\" is a Portuguese slang that means to help someone out or to find a workaround for a problem. In English, a similar expression would be \"to lend a hand\" or \"to help out.\" This phrase conveys a sense of informal assistance or support.',\n",
       "    english_slang='lend a hand',\n",
       "    alternative_slangs=['help out', 'give a hand', 'pitch in'],\n",
       "    formality_level='L2'\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219fe937-db55-4e4a-aaea-f4ec2145a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-07-25T21:22:12.523101]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `portuguese_slang` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `english_slang` (str): \n",
      "3. `alternative_slangs` (list[str]): More equivalent alternative slangs.\n",
      "4. `formality_level` (Literal['L1', 'L2', 'L3', 'L4', 'L5']): Slang formality level. Lesser the number more informal.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## portuguese_slang ## ]]\n",
      "{portuguese_slang}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## english_slang ## ]]\n",
      "{english_slang}\n",
      "\n",
      "[[ ## alternative_slangs ## ]]\n",
      "{alternative_slangs}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
      "\n",
      "[[ ## formality_level ## ]]\n",
      "{formality_level}        # note: the value you produce must exactly match (no extra characters) one of: L1; L2; L3; L4; L5\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Find a Portuguese slang equivalance in English and classify it's formality level.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## portuguese_slang ## ]]\n",
      "quebrar o galho\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## english_slang ## ]]`, then `[[ ## alternative_slangs ## ]]` (must be formatted as a valid Python list[str]), then `[[ ## formality_level ## ]]` (must be formatted as a valid Python Literal['L1', 'L2', 'L3', 'L4', 'L5']), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "\"Quebrar o galho\" is a Portuguese slang that means to help someone out or to find a workaround for a problem. In English, a similar expression would be \"to lend a hand\" or \"to help out.\" This phrase conveys a sense of informal assistance or support.\n",
      "\n",
      "[[ ## english_slang ## ]]\n",
      "lend a hand\n",
      "\n",
      "[[ ## alternative_slangs ## ]]\n",
      "[\"help out\", \"give a hand\", \"pitch in\"]\n",
      "\n",
      "[[ ## formality_level ## ]]\n",
      "L2\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd201cef-c62a-4733-b80e-8bc0cb1ff5eb",
   "metadata": {},
   "source": [
    "## Changing the Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06863b2d-4043-49ed-9b32-6cbbd204c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=dspy.LM(\"openai/gpt-4o\"))\n",
    "dspy.configure(adapter=dspy.JSONAdapter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aafe0c3-ac7c-422d-8dfc-07b04496d797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 21:22:18 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    }
   ],
   "source": [
    "cot = dspy.ChainOfThought(SlangEquivalence)\n",
    "output = cot(portuguese_slang=\"quebrar o galho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7a56d0d-cb31-4a7c-9de5-39f7e9cfca4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='\"Quebrar o galho\" is a Portuguese slang expression that means to help someone out or to do a favor, often in a situation where a quick or temporary solution is needed. The English equivalent would be \"to help out\" or \"to lend a hand.\"',\n",
       "    english_slang='help out',\n",
       "    alternative_slangs=['lend a hand', 'do a favor', 'give a hand'],\n",
       "    formality_level='L3'\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2176914-8358-4062-a49b-8459d50f6887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-07-25T21:22:18.859567]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `portuguese_slang` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `english_slang` (str): \n",
      "3. `alternative_slangs` (list[str]): More equivalent alternative slangs.\n",
      "4. `formality_level` (Literal['L1', 'L2', 'L3', 'L4', 'L5']): Slang formality level. Lesser the number more informal.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## portuguese_slang ## ]]\n",
      "{portuguese_slang}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"{reasoning}\",\n",
      "  \"english_slang\": \"{english_slang}\",\n",
      "  \"alternative_slangs\": \"{alternative_slangs}        # note: the value you produce must adhere to the JSON schema: {\\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}\",\n",
      "  \"formality_level\": \"{formality_level}        # note: the value you produce must exactly match (no extra characters) one of: L1; L2; L3; L4; L5\"\n",
      "}\n",
      "In adhering to this structure, your objective is: \n",
      "        Find a Portuguese slang equivalance in English and classify it's formality level.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## portuguese_slang ## ]]\n",
      "quebrar o galho\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `reasoning`, then `english_slang`, then `alternative_slangs` (must be formatted as a valid Python list[str]), then `formality_level` (must be formatted as a valid Python Literal['L1', 'L2', 'L3', 'L4', 'L5']).\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m{\n",
      "  \"reasoning\": \"\\\"Quebrar o galho\\\" is a Portuguese slang expression that means to help someone out or to do a favor, often in a situation where a quick or temporary solution is needed. The English equivalent would be \\\"to help out\\\" or \\\"to lend a hand.\\\"\",\n",
      "  \"english_slang\": \"help out\",\n",
      "  \"alternative_slangs\": [\"lend a hand\", \"do a favor\", \"give a hand\"],\n",
      "  \"formality_level\": \"L3\"\n",
      "}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ff470-d224-4e73-a4fb-b129c00894e0",
   "metadata": {},
   "source": [
    "## Creating a Custom Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db9f0f53-7d5c-42d6-b4c3-dc6dd4733c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(\n",
    "    lm=dspy.LM(\"openai/gpt-4o-mini\"),\n",
    "    adapter=dspy.ChatAdapter(),\n",
    "    track_usage=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f789dd8-c42a-4e11-8de6-064e307cc5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkillIdentifier(dspy.Signature):\n",
    "    \"\"\"Given a job description, identify the most important technical skills needed for a successfully job appliance.\"\"\"\n",
    "\n",
    "    job_description: str = dspy.InputField()\n",
    "    tech_skills: list[str] = dspy.OutputField(\n",
    "        desc=\"Ordered technical skills from most important to less important\"\n",
    "    )\n",
    "\n",
    "\n",
    "class SkillSummary(dspy.Signature):\n",
    "    \"\"\"Given a technical skill make a short summary showing what is it about and give some examples during the explanation. Also include examples of project based ideas to prove the knowledge about the skill.\"\"\"\n",
    "\n",
    "    tech_skill: str = dspy.InputField()\n",
    "    skill_summary: str = dspy.OutputField(\n",
    "        desc=\"A Markdown-formatted summary section\"\n",
    "    )\n",
    "    project_based_examples: list[str] = dspy.OutputField()\n",
    "\n",
    "\n",
    "class DetailJob(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.skill_identifier = dspy.Predict(SkillIdentifier)\n",
    "        self.skill_summary = dspy.Predict(SkillSummary)\n",
    "\n",
    "    def forward(self, job_description, top_k=3):\n",
    "        skills_resp = self.skill_identifier(job_description=job_description)\n",
    "        print(f\"## IDENTIFIED SKILLS: {skills_resp.tech_skills}\")\n",
    "        for i, item in enumerate(skills_resp.tech_skills):\n",
    "            details_resp = self.skill_summary(tech_skill=item)\n",
    "\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"* SKILL: {item}\")\n",
    "            print(\"=\" * 50)\n",
    "            print(f\">> SUMMARY:\\n{details_resp.skill_summary}\")\n",
    "            print(\n",
    "                f\"---\\n>> PROJECT BASED IDEAS:\\n{details_resp.project_based_examples}\"\n",
    "            )\n",
    "\n",
    "            if i == top_k - 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c338ae7c-e76d-45e0-83b0-f41efb81b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"\"\"\n",
    "About the Role As an AI Research Engineer, you will: Build and maintain LLM-based and agentic product features, including\n",
    "rigorous evaluation, benchmarking and backtesting. Create systems that can improve over time based on feedback from humans\n",
    "in the loop, such as prompt optimisation and fine-tuning.s Explore applications of the latest developments of AI to enhance\n",
    "our product features, explainability, speed and accuracy. What You’ll Do AI features: Use the latest in LLMs, agents and\n",
    "computer vision to build systems that are faster, more thorough and more accurate than humans. Evals: Build benchmarks,\n",
    "evaluate backtests and analyse results to quantify our performance and prevent regressions. MLOps: Ensure that we maintain\n",
    "good practices around collecting and managing datasets, backtests and benchmarks to to maximise development velocity Prompt\n",
    "Engineering: Develop and test prompts to optimise model performance and deliver high-quality outputs. Model Fine-Tuning:\n",
    "Adapt and fine-tune large language models and vision models for specific use cases. Custom Model Training: Train and deploy\n",
    "bespoke AI models tailored to solve unique compliance challenges. Collaboration: Work closely with the engineering and\n",
    "product teams to translate customer needs into actionable AI solutions. Iterate: Continuously iterate on our AI systems to\n",
    "improve performance, reduce errors, and deliver value to customers. Our Culture 1. Own With Urgency As a startup, delivering\n",
    "value quickly is our superpower. We achieve this by valuing speed and ownership over perfection. We're not afraid to get our\n",
    "hands dirty, experiment, and iterate quickly to achieve our goals, and completely own the outcome. 2. Transparency We believe\n",
    "in open communication and full visibility across teams and roles. Decisions, successes, and failures are shared openly to\n",
    "foster trust and collaboration. 3. Customer First, Team Second, Self Last Our priority is creating value for our customers.\n",
    "We then focus on building a supportive, growth-oriented team environment, putting individual needs last to ensure collective\n",
    "success. What We’re Looking For Experience: 3+ years in an AI research or engineering role, with experience building and\n",
    "testing agentic systems. Technical Expertise: Hands-on experience with prompt engineering, fine-tuning pre-trained models,\n",
    "and training custom models, including vision models. Experience using TypeScript a plus. Product Mindset: Strong\n",
    "understanding of how AI can solve real-world problems, with a focus on customer needs. Interests: Ability to stay updated with\n",
    "the latest advancements in AI and apply them effectively. Collaboration: Excellent communication skills to work across teams\n",
    "and explain complex AI concepts to non-technical stakeholders. Ownership: A proactive, problem-solving mindset with the\n",
    "ability to take full responsibility for projects and outcomes. Growth-Oriented: Excited to learn new skills, tackle challenges,\n",
    "and adapt as the company scales.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "445c46e7-a3bc-4831-af6d-13db708d2201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## IDENTIFIED SKILLS: ['Prompt Engineering', 'Model Fine-Tuning', 'Custom Model Training', 'MLOps', 'LLM Development', 'Computer Vision', 'Benchmarking and Evaluation', 'TypeScript']\n",
      "==================================================\n",
      "* SKILL: Prompt Engineering\n",
      "==================================================\n",
      ">> SUMMARY:\n",
      "Prompt Engineering is the practice of designing and refining input prompts to effectively communicate with AI models, particularly in natural language processing. It involves understanding how to frame questions or statements to elicit the most accurate and relevant responses from AI systems. This skill is crucial for maximizing the utility of AI tools, as the quality of the output is often directly related to the clarity and specificity of the input. For example, a well-structured prompt can lead to more insightful answers, while vague prompts may yield less useful information.\n",
      "---\n",
      ">> PROJECT BASED IDEAS:\n",
      "['Develop a chatbot that uses prompt engineering to provide customer support, ensuring that the prompts guide users to articulate their issues clearly.', 'Create a content generation tool that utilizes prompt engineering to help writers brainstorm ideas based on specific themes or keywords.', 'Build a language translation application that employs prompt engineering to improve the accuracy of translations by providing context-aware prompts.', \"Design an educational tool that uses prompt engineering to generate personalized quizzes based on students' learning progress and preferences.\"]\n",
      "==================================================\n",
      "* SKILL: Model Fine-Tuning\n",
      "==================================================\n",
      ">> SUMMARY:\n",
      "Model fine-tuning is the process of taking a pre-trained machine learning model and adjusting its parameters on a new, often smaller dataset to improve its performance on a specific task. This technique leverages the knowledge the model has already acquired during its initial training phase, allowing it to adapt to new data with less computational cost and time. Fine-tuning is particularly useful in natural language processing (NLP) and computer vision, where large models can be trained on vast datasets and then refined for specific applications, such as sentiment analysis or image classification.\n",
      "---\n",
      ">> PROJECT BASED IDEAS:\n",
      "['Fine-tuning a BERT model for sentiment analysis on movie reviews to classify reviews as positive, negative, or neutral.', 'Adapting a pre-trained ResNet model to identify specific species of plants in images by training it on a smaller dataset of labeled plant images.', 'Using transfer learning to fine-tune a GPT-3 model for generating personalized email responses based on user input.', 'Fine-tuning a YOLOv5 model for real-time object detection in a custom video surveillance application.', 'Adjusting a pre-trained T5 model to summarize news articles in a specific domain, such as technology or health.']\n",
      "==================================================\n",
      "* SKILL: Custom Model Training\n",
      "==================================================\n",
      ">> SUMMARY:\n",
      "Custom model training involves the process of developing machine learning models tailored to specific datasets and requirements. This skill encompasses selecting appropriate algorithms, preprocessing data, tuning hyperparameters, and evaluating model performance. By training models on custom datasets, practitioners can achieve better accuracy and relevance for specific tasks, such as image recognition, natural language processing, or predictive analytics. For instance, a custom model can be trained to classify medical images or to analyze sentiment in customer reviews, providing insights that generic models may not capture.\n",
      "---\n",
      ">> PROJECT BASED IDEAS:\n",
      "['Develop a custom image classification model to identify different species of plants using a dataset of labeled images.', 'Create a sentiment analysis model that classifies customer feedback into positive, negative, and neutral categories based on a custom dataset.', 'Train a recommendation system using collaborative filtering techniques on user behavior data from an e-commerce platform.', \"Build a custom natural language processing model to extract key information from legal documents, tailored to a specific law firm's needs.\", 'Implement a time series forecasting model to predict stock prices based on historical data, adjusting for seasonal trends and anomalies.']\n"
     ]
    }
   ],
   "source": [
    "job_detail = DetailJob()\n",
    "job_detail(job_description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c228b-2eec-4f9d-954a-4b10350dadec",
   "metadata": {},
   "source": [
    "## Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b2c5282-3d59-4378-b8a9-4dc5c7bd5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_detail.save(\"data/dspy_modules/jobdetail.json\", save_program=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c7e2c0c-6714-445a-9aec-a394b990ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_detail.load(\"data/dspy_modules/jobdetail.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42beea32-d82f-416f-9760-22f423d8161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_detail.save(\"data/dspy_modules/jobdetail/\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "725b9529-5405-4dc4-a8fd-5ca609fc37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_module = dspy.load(\"data/dspy_modules/jobdetail/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f75635d-01cd-431d-b4b2-dcfaf23170c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0532c",
   "metadata": {},
   "source": [
    "## Optimizing Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86edd5",
   "metadata": {},
   "source": [
    "### RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "182b5b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/262207438023260723', creation_time=1753487661794, experiment_id='262207438023260723', last_update_time=1753487661794, lifecycle_stage='active', name='my-local-experiment-part-2', tags={}>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"my-local-experiment-part-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c8263a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(query: str) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url=\"http://20.102.90.50:2017/wiki17_abstracts\")(\n",
    "        query, k=3\n",
    "    )\n",
    "    return [x[\"text\"] for x in results]\n",
    "\n",
    "\n",
    "react = dspy.ReAct(\"question -> answer\", tools=[search_wikipedia])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1af45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "trainset = []\n",
    "with open(\"data/dspy_data/trainset.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        trainset.append(\n",
    "            dspy.Example(**json.loads(line)).with_inputs(\"question\")\n",
    "        )\n",
    "\n",
    "# load validation dataset\n",
    "valset = []\n",
    "with open(\"data/dspy_data/valset.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        valset.append(dspy.Example(**json.loads(line)).with_inputs(\"question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb8afa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'question': 'So Long, Scarecrow is titled in reference to which 1939 musical fantasy film?', 'answer': 'The Wizard of Oz'}) (input_keys={'question'})\n"
     ]
    }
   ],
   "source": [
    "# check data example\n",
    "print(trainset[85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e75b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = dspy.MIPROv2(\n",
    "    metric=dspy.evaluate.answer_exact_match, auto=\"light\", num_threads=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "764e8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dspy.cache.load_memory_cache(\"./memory_cache.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_react = tp.compile(\n",
    "    react,\n",
    "    trainset=trainset,\n",
    "    valset=valset,\n",
    "    requires_permission_to_run=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_react.react.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_react.react.demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = dspy.Evaluate(\n",
    "    metric=dspy.evaluate.answer_exact_match,\n",
    "    devset=valset,\n",
    "    display_table=True,\n",
    "    display_progress=True,\n",
    "    num_threads=24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_score = evaluator(react)\n",
    "print(f\"Original score: {original_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_score = evaluator(optimized_react)\n",
    "print(f\"Optimized score: {optimized_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lab-kernel",
   "language": "python",
   "name": "ml-lab-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
