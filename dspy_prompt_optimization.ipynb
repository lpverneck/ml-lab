{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74532c91-d351-48ec-a213-8f17b63ddff5",
   "metadata": {},
   "source": [
    "## Building Blocks of DSPy\n",
    "\n",
    "- **dspy.Signature**: define the input/output contract of DSPy module.\n",
    "- **dspy.Module**: define the logic of interacting with LLMs.\n",
    "\n",
    "## Advantages\n",
    "\n",
    "- LM-agnostic programming\n",
    "- Seamless productization\n",
    "- Automatic program optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1657bb-5b38-452a-82c0-479f3fe77a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import mlflow\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "dspy.settings.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"), track_usage=True)\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"my-local-experiment\")\n",
    "mlflow.dspy.autolog()\n",
    "\n",
    "# running local MLflow server\n",
    "# mlflow server --host 127.0.0.1 --port 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4349fe8f-b531-4f77-a3d2-cc1c3de068cc",
   "metadata": {},
   "source": [
    "## Class-based Signature Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb30c9f-5691-4af6-a80d-e5eb84071c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlangEquivalence(dspy.Signature):\n",
    "    \"\"\"Find a Portuguese slang equivalance in English and classify it's formality level.\"\"\"\n",
    "\n",
    "    # inputs\n",
    "    portuguese_slang: str = dspy.InputField()\n",
    "    # outputs\n",
    "    english_slang: str = dspy.OutputField()\n",
    "    alternative_slangs: list[str] = dspy.OutputField(\n",
    "        desc=\"More equivalent alternative slangs.\"\n",
    "    )\n",
    "    formality_level: Literal[\"L1\", \"L2\", \"L3\", \"L4\", \"L5\"] = dspy.OutputField(\n",
    "        desc=\"Slang formality level. Lesser the number more informal.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef6efc-e506-4951-8fb7-cf4d40b29139",
   "metadata": {},
   "source": [
    "## String-based Signature Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8602339-07f1-426a-aa66-412eff5c558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_equivalance = dspy.make_signature(\n",
    "    \"portuguese_slang -> english_slang: str, alternative_slangs: list[str]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd220fd9-776a-4cf8-9aac-ecdc20b0b2b8",
   "metadata": {},
   "source": [
    "## LM Interaction via Module Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9197e36-3e47-44cf-b875-d75024b02aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = dspy.Predict(slang_equivalance)\n",
    "output = predict(portuguese_slang=\"Boiar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf4905-c27a-4574-96d5-bd8030c7bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0fe47-f747-4488-81d6-7aee0c90127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"English equivalent slang: {output['english_slang']}\\nAlternative slangs: {output.alternative_slangs}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3862b56-8040-4d97-a992-fe421d4c0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot = dspy.ChainOfThought(SlangEquivalence)\n",
    "output = cot(portuguese_slang=\"quebrar o galho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f61253-4975-4f69-aeed-b54e1bb329b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fe937-db55-4e4a-aaea-f4ec2145a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd201cef-c62a-4733-b80e-8bc0cb1ff5eb",
   "metadata": {},
   "source": [
    "## Changing the Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06863b2d-4043-49ed-9b32-6cbbd204c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=dspy.LM(\"openai/gpt-4o\"))\n",
    "dspy.configure(adapter=dspy.JSONAdapter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafe0c3-ac7c-422d-8dfc-07b04496d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot = dspy.ChainOfThought(SlangEquivalence)\n",
    "output = cot(portuguese_slang=\"quebrar o galho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a56d0d-cb31-4a7c-9de5-39f7e9cfca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2176914-8358-4062-a49b-8459d50f6887",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ff470-d224-4e73-a4fb-b129c00894e0",
   "metadata": {},
   "source": [
    "## Creating a Custom Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f0f53-7d5c-42d6-b4c3-dc6dd4733c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"), track_usage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f789dd8-c42a-4e11-8de6-064e307cc5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkillIdentifier(dspy.Signature):\n",
    "    \"\"\"Given a job description, identify the most important technical skills needed for a successfully job appliance.\"\"\"\n",
    "\n",
    "    job_description: str = dspy.InputField()\n",
    "    tech_skills: list[str] = dspy.OutputField(\n",
    "        desc=\"Ordered technical skills from most important to less important\"\n",
    "    )\n",
    "\n",
    "\n",
    "class SkillSummary(dspy.Signature):\n",
    "    \"\"\"Given a technical skill make a short summary showing what is it about and give some examples during the explanation. Also include examples of project based ideas to prove the knowledge about the skill.\"\"\"\n",
    "\n",
    "    tech_skill: str = dspy.InputField()\n",
    "    skill_summary: str = dspy.OutputField(\n",
    "        desc=\"A Markdown-formatted summary section\"\n",
    "    )\n",
    "    project_based_examples: list[str] = dspy.OutputField()\n",
    "\n",
    "\n",
    "class DetailJob(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.skill_identifier = dspy.Predict(SkillIdentifier)\n",
    "        self.skill_summary = dspy.Predict(SkillSummary)\n",
    "\n",
    "    def forward(self, job_description, top_k=3):\n",
    "        skills_resp = self.skill_identifier(job_description=job_description)\n",
    "        print(f\"## IDENTIFIED SKILLS: {skills_resp.tech_skills}\")\n",
    "        for i, item in enumerate(skills_resp.tech_skills):\n",
    "            details_resp = self.skill_summary(tech_skill=item)\n",
    "\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"* SKILL: {item}\")\n",
    "            print(\"=\" * 50)\n",
    "            print(f\">> SUMMARY:\\n{details_resp.skill_summary}\")\n",
    "            print(\n",
    "                f\"---\\n>> PROJECT BASED IDEAS:\\n{details_resp.project_based_examples}\"\n",
    "            )\n",
    "\n",
    "            if i == top_k - 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338ae7c-e76d-45e0-83b0-f41efb81b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"\"\"\n",
    "About the Role As an AI Research Engineer, you will: Build and maintain LLM-based and agentic product features, including\n",
    "rigorous evaluation, benchmarking and backtesting. Create systems that can improve over time based on feedback from humans\n",
    "in the loop, such as prompt optimisation and fine-tuning.s Explore applications of the latest developments of AI to enhance\n",
    "our product features, explainability, speed and accuracy. What You’ll Do AI features: Use the latest in LLMs, agents and\n",
    "computer vision to build systems that are faster, more thorough and more accurate than humans. Evals: Build benchmarks,\n",
    "evaluate backtests and analyse results to quantify our performance and prevent regressions. MLOps: Ensure that we maintain\n",
    "good practices around collecting and managing datasets, backtests and benchmarks to to maximise development velocity Prompt\n",
    "Engineering: Develop and test prompts to optimise model performance and deliver high-quality outputs. Model Fine-Tuning:\n",
    "Adapt and fine-tune large language models and vision models for specific use cases. Custom Model Training: Train and deploy\n",
    "bespoke AI models tailored to solve unique compliance challenges. Collaboration: Work closely with the engineering and\n",
    "product teams to translate customer needs into actionable AI solutions. Iterate: Continuously iterate on our AI systems to\n",
    "improve performance, reduce errors, and deliver value to customers. Our Culture 1. Own With Urgency As a startup, delivering\n",
    "value quickly is our superpower. We achieve this by valuing speed and ownership over perfection. We're not afraid to get our\n",
    "hands dirty, experiment, and iterate quickly to achieve our goals, and completely own the outcome. 2. Transparency We believe\n",
    "in open communication and full visibility across teams and roles. Decisions, successes, and failures are shared openly to\n",
    "foster trust and collaboration. 3. Customer First, Team Second, Self Last Our priority is creating value for our customers.\n",
    "We then focus on building a supportive, growth-oriented team environment, putting individual needs last to ensure collective\n",
    "success. What We’re Looking For Experience: 3+ years in an AI research or engineering role, with experience building and\n",
    "testing agentic systems. Technical Expertise: Hands-on experience with prompt engineering, fine-tuning pre-trained models,\n",
    "and training custom models, including vision models. Experience using TypeScript a plus. Product Mindset: Strong\n",
    "understanding of how AI can solve real-world problems, with a focus on customer needs. Interests: Ability to stay updated with\n",
    "the latest advancements in AI and apply them effectively. Collaboration: Excellent communication skills to work across teams\n",
    "and explain complex AI concepts to non-technical stakeholders. Ownership: A proactive, problem-solving mindset with the\n",
    "ability to take full responsibility for projects and outcomes. Growth-Oriented: Excited to learn new skills, tackle challenges,\n",
    "and adapt as the company scales.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c46e7-a3bc-4831-af6d-13db708d2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_detail = DetailJob()\n",
    "job_detail(job_description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c228b-2eec-4f9d-954a-4b10350dadec",
   "metadata": {},
   "source": [
    "## Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c5282-3d59-4378-b8a9-4dc5c7bd5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_detail.save(\"data/dspy_modules/jobdetail.json\", save_program=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e2c0c-6714-445a-9aec-a394b990ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_detail.load(\"data/dspy_modules/jobdetail.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42beea32-d82f-416f-9760-22f423d8161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_detail.save(\"data/dspy_modules/jobdetail/\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b9529-5405-4dc4-a8fd-5ca609fc37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_module = dspy.load(\"data/dspy_modules/jobdetail/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75635d-01cd-431d-b4b2-dcfaf23170c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_module()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lab-kernel",
   "language": "python",
   "name": "ml-lab-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
